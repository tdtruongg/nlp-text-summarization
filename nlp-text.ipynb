{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce1f8bc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers torch numpy scikit-learn nltk rouge-score datasets sentencepiece tqdm\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, T5Tokenizer, T5ForConditionalGeneration, AutoModel\n",
    "from rouge_score import rouge_scorer\n",
    "import numpy as np\n",
    "import nltk\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4645cc8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Tải tập dữ liệu test\n",
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"test\")\n",
    "\n",
    "# Định nghĩa các hằng số\n",
    "T5_MODEL = 't5-base'\n",
    "BERT_MODEL = 'bert-base-uncased'\n",
    "MAX_LENGTH = 512\n",
    "SUMMARY_MAX_LENGTH = 150\n",
    "\n",
    "# Tải Tokenizer\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL)\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained(T5_MODEL)\n",
    "\n",
    "# Tải Mô hình\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained(T5_MODEL)\n",
    "bert_model = AutoModel.from_pretrained(BERT_MODEL)\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8428a9c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- TÓM TẮT TRÍCH CHỌN (BERT EXTRACTIVE) ---\n",
    "def bert_extractive_summarize(article, max_sentences=5):\n",
    "    \"\"\"Thực hiện tóm tắt Extractive dựa trên BERT embeddings.\"\"\"\n",
    "    try:\n",
    "        nltk.data.find('tokenizers/punkt')\n",
    "    except nltk.downloader.DownloadError:\n",
    "        nltk.download('punkt')\n",
    "\n",
    "    sentences = nltk.sent_tokenize(article)\n",
    "    if not sentences:\n",
    "        return \"\"\n",
    "\n",
    "    # Tính Embedding cho toàn bộ văn bản (Doc Embedding)\n",
    "    inputs_doc = bert_tokenizer(article, return_tensors='pt', truncation=True, padding=True, max_length=MAX_LENGTH)\n",
    "    with torch.no_grad():\n",
    "        doc_outputs = bert_model(**inputs_doc)\n",
    "    doc_embedding = doc_outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "    doc_embedding = doc_embedding.reshape(1, -1)\n",
    "\n",
    "    # Tính Embedding cho từng câu (Sentence Embeddings)\n",
    "    sent_embeddings = []\n",
    "    for sentence in sentences:\n",
    "        inputs_sent = bert_tokenizer(sentence, return_tensors='pt', truncation=True, padding=True)\n",
    "        with torch.no_grad():\n",
    "            sent_outputs = bert_model(**inputs_sent)\n",
    "        sent_embedding = sent_outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "        sent_embeddings.append(sent_embedding)\n",
    "\n",
    "    sent_embeddings_array = np.array(sent_embeddings)\n",
    "\n",
    "    # Tính điểm quan trọng (Cosine Similarity)\n",
    "    scores = cosine_similarity(sent_embeddings_array, doc_embedding).flatten()\n",
    "\n",
    "    # Trích chọn và sắp xếp\n",
    "    ranked_indices = np.argsort(scores)[::-1]\n",
    "    num_to_select = min(len(sentences), max_sentences)\n",
    "    selected_indices = sorted(ranked_indices[:num_to_select])\n",
    "\n",
    "    return \" \".join([sentences[i] for i in selected_indices])\n",
    "\n",
    "# --- TÓM TẮT TRỪU TƯỢNG (T5 ABSTRACTIVE) ---\n",
    "def t5_abstractive_summarize(article, max_len=SUMMARY_MAX_LENGTH, min_len=40, num_beams=4):\n",
    "    \"\"\"Thực hiện tóm tắt Abstractive bằng mô hình T5.\"\"\"\n",
    "\n",
    "    # Thêm prefix theo yêu cầu của T5\n",
    "    input_text = \"summarize: \" + article\n",
    "\n",
    "    # Mã hóa đầu vào\n",
    "    inputs = t5_tokenizer(input_text, max_length=MAX_LENGTH, return_tensors='pt', truncation=True)\n",
    "\n",
    "    # Sinh chuỗi (sử dụng Beam Search)\n",
    "    summary_ids = t5_model.generate(\n",
    "        inputs['input_ids'],\n",
    "        num_beams=num_beams,\n",
    "        max_length=max_len,\n",
    "        min_length=min_len,\n",
    "        length_penalty=2.0,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    # Giải mã đầu ra\n",
    "    abstractive_summary = t5_tokenizer.decode(summary_ids.squeeze(), skip_special_tokens=True)\n",
    "\n",
    "    return abstractive_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7b2413",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt_tab')\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt_tab')\n",
    "    nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391b8963",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sample_index = 42\n",
    "article_text = dataset[sample_index]['article']\n",
    "reference_summary = dataset[sample_index]['highlights']\n",
    "\n",
    "# --- Tóm tắt Extractive (BERT) ---\n",
    "ext_summary = bert_extractive_summarize(article_text, max_sentences=4)\n",
    "ext_scores = scorer.score(reference_summary, ext_summary)\n",
    "\n",
    "# --- Tóm tắt Abstractive (T5) ---\n",
    "abs_summary = t5_abstractive_summarize(article_text)\n",
    "abs_scores = scorer.score(reference_summary, abs_summary)\n",
    "\n",
    "print(\"--------------------------------------------------\")\n",
    "print(f\"Văn bản gốc (trích đoạn): {article_text[:400]}...\")\n",
    "print(\"\\n--- Tóm tắt Tham chiếu ---\")\n",
    "print(reference_summary)\n",
    "\n",
    "print(\"\\n--- 1. Extractive (BERT) ---\")\n",
    "print(ext_summary)\n",
    "print(f\"ROUGE-L F1: {ext_scores['rougeL'].fmeasure:.4f}\")\n",
    "\n",
    "print(\"\\n--- 2. Abstractive (T5) ---\")\n",
    "print(abs_summary)\n",
    "print(f\"ROUGE-L F1: {abs_scores['rougeL'].fmeasure:.4f}\")\n",
    "print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61c901e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "N_SAMPLES = 100\n",
    "dataset_subset = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=f\"test[:{N_SAMPLES}]\")\n",
    "\n",
    "\n",
    "results = {\n",
    "    'extractive': {'rouge1': [], 'rouge2': [], 'rougeL': []},\n",
    "    'abstractive': {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "}\n",
    "\n",
    "print(f\"Bắt đầu đánh giá ROUGE trên {N_SAMPLES} mẫu...\")\n",
    "\n",
    "for i in range(N_SAMPLES):\n",
    "    article = dataset_subset[i]['article']\n",
    "    reference = dataset_subset[i]['highlights']\n",
    "\n",
    "    #  Tóm tắt Extractive (BERT)\n",
    "    try:\n",
    "        ext_summary = bert_extractive_summarize(article, max_sentences=4)\n",
    "        ext_scores = scorer.score(reference, ext_summary)\n",
    "        for key in results['extractive']:\n",
    "            results['extractive'][key].append(ext_scores[key].fmeasure)\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi Extractive ở mẫu {i}: {e}\")\n",
    "        continue\n",
    "\n",
    "    #  Tóm tắt Abstractive (T5)\n",
    "    try:\n",
    "        abs_summary = t5_abstractive_summarize(article)\n",
    "        abs_scores = scorer.score(reference, abs_summary)\n",
    "        for key in results['abstractive']:\n",
    "            results['abstractive'][key].append(abs_scores[key].fmeasure)\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi Abstractive ở mẫu {i}: {e}\")\n",
    "        continue\n",
    "\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"Đã xử lý {i + 1}/{N_SAMPLES} mẫu.\")\n",
    "\n",
    "# Tính điểm trung bình cuối cùng\n",
    "avg_ext_results = {k: np.mean(v) for k, v in results['extractive'].items()}\n",
    "avg_abs_results = {k: np.mean(v) for k, v in results['abstractive'].items()}\n",
    "\n",
    "print(\"\\n--- KẾT QUẢ ROUGE TRUNG BÌNH ---\")\n",
    "print(\"Extractive (BERT):\")\n",
    "for k, v in avg_ext_results.items():\n",
    "    print(f\"  {k.upper()} F1: {v:.4f}\")\n",
    "\n",
    "print(\"\\nAbstractive (T5):\")\n",
    "for k, v in avg_abs_results.items():\n",
    "    print(f\"  {k.upper()} F1: {v:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
